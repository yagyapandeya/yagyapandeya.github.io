<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Yagya R Panddeya | Resume</title>
        <link rel="stylesheet" href="css/style.css">
        <link href="https://fonts.googleapis.com/css?family=Merriweather:300,400,700|Source+Sans+Pro:400,400i" rel="stylesheet">

	<meta charset="utf-8">
    	<meta name="description" content="Jacopo de Berardinis information page.">
    	<meta name="keywords" content="Jacopo de Berardinis, Tangramob">
    	<meta name="author" content="Jacopo de Berardinis">
    	<!-- Semantic UI + Semantic Icons -->
    	<link rel="stylesheet" type="text/css" href="css/semantic.min.css">
    	<link rel="stylesheet" type="text/css" href="css/icon.min.css">
    	<link href="https://fonts.googleapis.com/css?family=Raleway:200,300,400" rel="stylesheet">
    	<!-- CSS main file -->
    	<link rel="stylesheet" type="text/css" href="css/main.css">
	<link rel="icon" href="imgs/Yash2.png">

    <body>

	<div id="header" class="bgimage">
      	<div id="headerinfo">
        <img src="imgs/yy.jpg" class="ui small card image imgjaco">
        <div id="headertext">
          <p id="headername"><span style="font-weight:1000">Yagya Raj Pandeya, Ph.D.</p>
          <p id="headerrole">Machine Learning Engineer at Jeonbuk National University</p>
          <!-- <p id="headermail">yagyapandeya@gmail.com</p> -->
          <div id="social-icons">
            <!-- Email reference --->
            <a href="mailto:yagyapandeya@gmail.com"><img src="imgs/mail.png"></a>
            <!-- Scholar reference --->
            <a href="https://scholar.google.com/citations?user=EYFaLysAAAAJ&hl=en"><img src="imgs/google_scholar.png"></a>
            <!-- Linkedin --->
            <a href="https://www.linkedin.com/in/yagya-pandeya-b4947116b/"><img src="imgs/linkedin.png"></a>
            <!-- Researchgate profile -->
            <a href="https://www.researchgate.net/profile/Yagya_Raj_Pandeya"><img src="imgs/rgate.png"></a>
            <!-- Github -->
            <a href="https://github.com/yagyapandeya"><img src="imgs/github.png"></a>
          </div>
        </div>
      	</div>
    	</div>



        <div class="page">
		<div class="section row">
                <div class="contact-info col-right">
			<div><!--img src="yy.jpg" class="ui small card image imgjaco"--></div>
			<div>Citizenship: Nepal</div>
                    	<div>Permanent Address: Jhalari-7, Kanchanpur, Nepal</div>
			<div>Mailing Address: Jeonbuk National University, Jeonju city, South Korea</div>
			<div>Date of birth: 25th July, 1988</div>
			<div>Phone: (+82)01044049848</div>
                    <div><a href="mailto:yagyapandeya@gmail.com">yagyapandeya@gmail.com</a></div>
                </div>
            </div>
	
	<div class="section row">
                <h2 class="col">Carrier Objectives</h2>
                <div class="section-text col-right">
                    <h3><span class="emph">An enthusiastic and adaptive person with a broad and acute interest 
			in the discovery of new innovative information technologies. 
			I particularly enjoy collaborating with tech exports from different 
			disciplines of computer science to develop new skills and solve new challenges.</h3>  
            </div></div>
	
	<div class="section row">
                <h2 class="col">Bio</h2>
                <div class="section-text col-right">
                    <div>I am a researcher in Computer Science at the <a href="http://www.jbnu.ac.kr/eng/"><span class="emph">Jeonbuk National University</a>, affiliated with the <a href="http://gurutech.com.np/"><span class="emph">Guru technology</a> research group in Nepal. 
			My current project consists of applying deep learning methods in the field of animal sound behavior analysis, music information retrieval,
			 music video emotion analysis, music source separation, and object detection, with the aim of devising quantitative measures in affective computing and sound localization. 
			My research interest includes multi-level classification, unsupervised learning, self-supervised learning, meta-learning and incremental learning. </div>
		<div>I received Ph.D. in Computer Engineering from Jeonbuk National University, South Korea. I worked on animal sound localization and classification, affective computing in music video and music source separation. 
		I proposed five datasets in this domain to train the deep neural network and made public to support new researchers. My thesis work includes music video affective computing with supervised and unsupervised technology. 
		I proposed novel datasets, convolution techniques, and unimodal and multimodal architectures using music, video, and facial expressions from the music video. </div>
		<div>Prior to embarking on the insanity of the doctoral studies, I received an ME in Computer Engineering from the <a href="https://pu.edu.np/"><span class="emph">Pokhara University</a>, Nepal. 
		In my master thesis work, I worked on data communication and information processing using multiple antenna technology.</div>
		<div>A few years before, I received a BE in Computer Engineering from the <a href="https://pu.edu.np/"><span class="emph">Pokhara University</a>, with a thesis investigating home security system using microcontroller and sensor technology.</div> 
           
            </div></div>

            <div class="section row">
                <h2 class="col">Educations</h2>
                <div class="section-text col-right">
		<div><a href="http://www.jbnu.ac.kr/eng/"><h3><span class="emph">Jeonbuk National University</h3></a></div>
                    <div>Major in Machine Learning and Deep Neural Networks</div>
                    <div class="row">
                        <div class="col light">CGPA: 4.43/4.50</div>
                        <div class="col-right light">Sep. 2017 - Feb. 2021</div>
                    </div>
		<div><a href="https://pu.edu.np/"><h3><span class="emph">Pokhara University</h3></a></div>
                    <div><a href="https://ncit.edu.np/">Nepal College of Information Technology, Balkumari, Lalitpur(PU Affiliated College)</a></div>
                    <div class="row">
                        <div class="col light">Rank: Dean's List (CGPA: 3.97/4)</div>
                        <div class="col-right light">Aug. 2010 to May 2013 </div>
                    </div>
		
		<div><a href="https://pu.edu.np/"><h3><span class="emph">Pokhara University(PU)</h3></a></div>
                    <div><a href="http://nast.edu.np/">National Academy of Science and Technology, Dhangadhi, Kailali(PU Affiliated College)</a></div>
                    <div class="row">
                        <div class="col light">Rank: CGPA: 3.54/4</div>
                        <div class="col-right light">Aug. 2005 to Oct. 2010 </div>
                    </div>
		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB)</h3></a></div>
                    <div><a href="http://radianths.edu.np/">Radiant Secondary School, Mahendranagar, Kanchanpur(Under NEB)(Class XII)</a></div>
                    <div class="row">
                        <div class="col light">OVERALL PERCENTAGE: 55%</div>
                        <div class="col-right light">2005 </div>
                    </div>
		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB)</h3></a></div>
                    <div>Shree Radha-Krishna Secondary School, Tiltali, Doti(Under Government of Nepal)(Class X)</div>
                    <div class="row">
                        <div class="col light">OVERALL PERCENTAGE: 74%</div>
                        <div class="col-right light">2003 </div>
                    </div>
                </div>
            </div>

	<div class="section row">
                <h2 class="col">WORK EXPERIENCES</h2>
                <div class="section-text col-right">
		<div><a href="http://ailab.jbnu.ac.kr/"><h3><span class="emph">Fuzzy Logic and Artificial Intelligence Laboratory at Jeonbuk National University</h3></a></div>
                    <div>Machine learning and Deep learning based research</div>
		<div>Address: Jeonju City, South Korea</div>
                    <div class="row">
                        <div class="col light">Status: Researcher </div>
                        <div class="col-right light">27 April 2017 - Ongoing</div>
                    </div>

		<div><a href="http://www.moha.gov.np/"><h3>Ministry of Home Affairs (Government of Nepal)</h3></a></div>
                    <div>National Information Collection and Transfer </div>
			<div>Address: Singhdurbar, Kathmandu, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: IT officer</div>
                        <div class="col-right light">27 April 2015 - Aug 22 2016</div>
                    </div>
		
		<div><a href="http://nast.edu.np/"><h3><span class="emph">Head of Computer Engineering Department</h3></a></div>
                    <div>Assistant Professor and Department head. </div>
			<div>Address: Dhangadhi, Kailali, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: Head of Department</div>
                        <div class="col-right light">12 Feb 2013 - 27 April 2015</div>
                    </div>

		<div><a href="https://www.wvi.org/nepal"><h3><span class="emph">World Vision International Nepal</h3></a></div>
                    <div>Database management. </div>
			<div>Address: Dhangadhi, Kailali, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: IT officer (Internship)</div>
                        <div class="col-right light">21 Aug. 2010 - 10 Sep. 2010</div>
                    </div>

		<div><a href="https://www.rvwrmp.org.np/"><h3><span class="emph">Rural Village Water Resources Management Project (RVWRMP)</h3></a></div>
                    	<div>Database management.</div>
			<div>Address: Dhangadhi, Kailali, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: IT officer (Internship)</div>
                        <div class="col-right light">4 Dec. 2009 - 12 Feb. 2010</div>
                    </div>
		
                </div>
            </div>


            <div class="section row">
                <h2 class="col">PROJECTS</h2>

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Affective Computing (Unsupervised)</h3>
                        </div>
                    </div>
                        <div class="col-right light">Sep. 2020 - Jan. 2021</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/unsuper_MV.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b>Music video Emotion Classification using Slow-fast Audio-video Network and Unsupervised Feature Representation.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Unsupervised and supervised music video emotion classification dataset</li>
                        <li>Autoencoder architecture with audio adn video information.</li>
                        <li>Slow-fast audio-video network to capture spatial and temporal information of music and video.</li>
			<li>Train time information sharing and boosting modules.</li>
			<li>Under review.</li>
               
		</div>


		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Affective Computing (Supervised)</h3>
                        </div>
                    </div>
                        <div class="col-right light">Sep. 2020 - Jan. 2021</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Super_MV.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b>Deep Learning-Based Multimodal Methods for Emotion Classification in Music Video Contents.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music video emotion classification dataset (Inproved and Extended version)</li>
                        <li>Ablation study on unimodla and multimodal using music, video and facial expression.</li>
                        <li>Network complexity reduction using novel channel and filter separable convolution.</li>
			<li>Train time information sharing and boosting modules.</li>
			<li>End-to-end training, better result on visual and statistical analysis.</li>
			<li>Under review.</li>
               
		</div>

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Facemask States Detection</h3>
                        </div>
                    </div>
                        <div class="col-right light">Nov. 2020 - Jan. 2021</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Face_mask.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b>Deep Learning Based Face Mask Status Detection for COVID-19.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Semi-automatic visual object labeling tool </li>
                        <li>Facemask detection dataset with three cass categories of with mask, without mask and wrong weared mask.</li>
                        <li>Mask detetion using Faster-RCNN, Cascade FRCNN, FPN and Cascade FPN.</li>
			<li>Comparision, visualization and analysis of sustem ability and applications.</li>
			<li>Under review.</li>
               
                    </div>




		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Sound Event Labeling Tool</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Cow_GUI.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b> A Semi-automatic Sound Annotation Tool for Audio/Video data.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Semi-automatic sound event annotation tool using audio and video as input.</li>
                        <li>Automatic event detector is used to detect the audio event.</li>
                        <li>Based on the automatic detector result, an human annotation have to refine the annotation boundary.</li>
			<li>Easy to use, better audio visualization, python based and output in easy CSV data file.</li>
                        <li>Diversified annotation tool for any rare sound event.</li>
			<li>Under review.</li>
               
                    </div>
		
		<div class="section-text col-right">
                    <div class="row">
                        <div class="col">
                            <h3>Music Source Seperation</h3>
                        </div>
                    </div>
                        <div class="col-right light">June 2020 - Nov. 2020</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/SS.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9257356">Parallel Stacked Hourglass Network for Music Source Separation.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li><b>Prepared Korean traditional song (Pansori) dataset with 3 sources.</li>
			<li>Korean traditional music Pansori dataset, MIR-1K dataset, and DSD100 dataset used in experiment. </li>
                        <li>Proposed a novel parallel stacked hourglass network (PSHN) with multiple band spectrograms.</li>
                        <li>Ablation study on proposed and past architecture.</li>
                        <li>State-of-art result.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Nov. 2020</li>
               
                    </div>

		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>CNN Based Sound Event Detection in Cowshed</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Jeju_conf.jpg" scale:2>
       		 	</div>
			</div>


                    <ul class="desc">
                        <li>Article title:<b><a href="http://sigongji.ictc.org/wp/SessionPaperList.asp?code=Session%20III-1">Sound Event Detection in Cowshed using Synthetic data and Convolutional Neural Network</a></b><b><span style="color:#FF5733;">[IEEE Conference]</span></b></li>
                        <li>CNN based sound event detection.</li>
			<li>Sound event annotaion tool.</li>
                        <li>Sound localization and classification.</li>
			<li>Puplished on <b><a href="http://ictc.org/"> ICTC2020 </a></b>in Sep. 2020</li>
               
                    </div>

		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Cow Sound Event Localization and Classification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Cow_SED.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9187249/">Visual Object Detector for Cow Sound Event Detection</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Cow sound event detection dataset with 4 class categories.</li>
			<li>CNN used for sound event detection using Cow sound dataset and <a href="https://urbansounddataset.weebly.com/urbansound8k.html">UrbanSound8K dataset.</a></li>
                        <li>Visual object detection architecture (F-RCNN, CF-RCNN, FPN, C-FPC) used for audio event detection (in Log Mel-Spectrogram).</li>
			<li>Compare the proposed CNN and Visual object detection architecture using three test dataset.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Sep. 2020</li>
               
                    </div>
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music-Video Emotion Classification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Jan. 2019 - Sep. 2019</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/I3D_CNN.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://link.springer.com/article/10.1007/s11042-020-08836-3">Deep Learning-Based Late Fusion of Multimodal Information for Emotion Classification of Music Video</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music-Video emotion classification using audio and video multimodal network architecture.</li>
                        <li>Use pretrained CNN for audio and 3D video model (I3D and C3D).</li>
			<li>The network learned features ate late fused and compare the impact of network feature fusion.</li>
                        <li>Cross validation and network feature fusion.</li>
			<li>Puplished on <b><a href="https://www.springer.com/journal/11042"> Multimedia Tools and Applications </a></b>in Sep. 2020</li>
               
                    </div>
		
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Emotion Analysis</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2018 - March 2019</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/mv_conf.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://www.semanticscholar.org/paper/Music-Video-Emotion-Analysis-Using-Late-Fusion-of-Pandeya-Lee/594b7ec2607cf220a8d3ff64340dd5607b56ecb2">Music-Video Emotion Analysis Using Late Fusion of Multimodal</a></b><b><span style="color:#FF5733;">[Conference]</span></b></li>
                        <li>Music video emotion dataset of six class category.</li>
                        <li>Audio-video multimodal architecture.</li>
			<li>C3D pretrained network and CNN pretrained audio network feature fusion.</li>
                        <li>Emotion representation in 2D emotion space.</li>
			<li>Puplished on <b><a href="http://www.allconfs.org/meeting/index_en.asp?id=5848"> ITEEE 2019 Conference </a></b>in 2019</li>
               
                    </div>
		

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Domestic Cat Sound Classification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2017 - Sep. 2018</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/CDBN.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://www.mdpi.com/2076-3417/8/10/1949">Domestic Cat Sound Classification Using Learned Features from Deep Neural Nets</a></b><b><span style="color:#FF5733;">[SCI Journal]</span></b></li>
                        <li>CNN and CDBN network architecture.</li>
                        <li>Cat sound dataset preparation of 10 class categories.</li>
			<li>Frequency division average pooling (FDAP) technique instead of global average pooling (GAP) to make a robust prediction using various frequency band features.</li>
                        <li>Audio augmentation and learned feature visualization.</li>
			<li>Puplished on <b><a href="https://www.mdpi.com/journal/applsci"> Applied Science </a></b>in Sep 2018</li>
               
                    </div>
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Domestic Cat Sound Classification using Transfer Learning</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2017 - March 2018</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/aspecus.jpg" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="http://doi.org/10.5391/IJFIS.2018.18.2.154">Domestic Cat Sound Classification Using Transfer Learning</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Cat sound dataset with 10 class categories.</li>
                        <li>Use pretrained CNN for feature extraction and make feature classification.</li>
			<li>Machine learning classifier and deep learning classifier comparision.</li>
                        <li>Ensemble and data augmentation.</li>
			<li>Puplished on <b><a href="http://www.ijfis.org/about/sub01.html"> International Journal of Fuzzy Logic and Intelligent Systems </a></b>in June 2018</li>
               
                    </div>
	</div>
	<div class="section row">
                <h2 class="col">Current Research</h2>
                <div class="section-text col-right">
                    <div><a>Music-Video emotion analysis.</a></div>
                    <div><a>Multiple action recognition in cowshed.</a></div>
                    <div><a>Plant disease detection.</a></div>
                    <div><a>Cattle emotion and behavior analysis.</a></div>
                    <div><a>Music source seperation.</a></div>

                </div>

            </div>
            <div class="section row">
                <h2 class="col">Achievements</h2>
                <div class="section-text col-right">

                    <div class="row subsection">
                        <li>Winner <a href="http://www.studyinkorea.go.kr/"><b>Korean Government Scholarship Program (KGSP) (2016)</b></a></li>
                        <li>Awarded by <b>Dean's List</b> of <a href="https://pu.edu.np/">Pokhara University</a> in 2014</li>
                            
                    </div>
                    
                </div>

            </div>
            <div class="section row">
                <h2 class="col">Language Skills</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>English Language</li>
                        <li>Korean Language</li>
                        <li>Hindi</li>
			<li>Nepali</li>
                    
                    </ul>

                    <ul class="skills" style="width:35%">
                        <li>Good</li>
                        <li>Moderate (1 year course)(<a href="https://www.topik.go.kr/usr/lang/index.do?home_seq=221">TOPIK</a>-3)</li>
                        <li>Very good</li>
			<li>Excellent</li>
                        
                    </ul>
                    
                </div>
            </div>
            <div class="section row">
                <h2 class="col">Techincal Skills</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>Programming Languages</li>
                        <li>Deep learning Framework</li>
                        <li>Platforms</li>
                        <li>Networking</li>
			<li>I.D.E Skills</li>
                    </ul>
                    <ul class="skills" style="width:35%">
                        <li>Python, C, C++, PHP</li>
                        <li>TensorFlow, Keras, PyTorch</li>
                        <li>Linux, Windows, CUDA/Docker</li>
			<li>Eclipse, UML, PyCharm </li>
                        
                    </ul>
                    
                </div>
            </div>
            
	
	<div class="section row">
                <h2 class="col">References</h2>
                <div class="section-text col-right">
		<div><a href="http://ailab.jbnu.ac.kr/intro_prof.php"><h3><span class="emph">Prof. Joonwhoan Lee</h3></a></div>
                    <div>Ph.D. Adviser</div>
			<div>Institude: <a href="https://www.jbnu.ac.kr/kor/">Jeonbuk National University</a></div>
			<div>Ph No.: +82-63-270-2406, +82-010-9855-2406</div>
			<div>Email: <a href="mailto:chlee@chonbuk.ac.kr">chlee@chonbuk.ac.kr</a></div>
		
		<div><a href="https://scholar.google.com/citations?user=S1dL69sAAAAJ&hl=en"><h3><span class="emph">Prof. Shashidhar Ram Joshi</h3></a></div>
                    <div>Master Adviser</div>
			<div>Institude: <a href="https://pu.edu.np/">Pokhara University</a></div>
			<div>Ph No.: +977-01-5534070 </div>
			<div>Email: <a href="mailto:srjoshi@ioe.edu.np">srjoshi@ioe.edu.np</a></div>
		
		<div><h3><span class="emph">Mr. SS Mudvari</h3></div>
                    <div>NAST Engineering College Principal</div>
			<div>Institude: <a href="http://nast.edu.np/">National Academy of Science & Technology</a></div>
			<div>Ph No.: +977-91-523312,521312 </div>
			<div>Email varify at: nastdhn@gmail.com, nastdhn@yahoo.com</div>
                </div>
            </div>

            </div>
        </div>
    </body>
    
            </html>
