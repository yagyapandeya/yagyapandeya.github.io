<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Yagya R Panddeya | Resume</title>
        <link rel="stylesheet" href="css/style.css">
        <link href="https://fonts.googleapis.com/css?family=Merriweather:300,400,700|Source+Sans+Pro:400,400i" rel="stylesheet">

	<meta charset="utf-8">
    	<meta name="description" content="Yagya Raj Pandeya information page.">
    	<meta name="keywords" content="Yagya Raj Pandeya, Tangramob">
    	<meta name="author" content="Yagya Raj Pandeya">
    	<!-- Semantic UI + Semantic Icons -->
    	<link rel="stylesheet" type="text/css" href="css/semantic.min.css">
    	<link rel="stylesheet" type="text/css" href="css/icon.min.css">
    	<link href="https://fonts.googleapis.com/css?family=Raleway:200,300,400" rel="stylesheet">
    	<!-- CSS main file -->
    	<link rel="stylesheet" type="text/css" href="css/main.css">
	<link rel="icon" href="imgs/pp.png">

    <body>

	<div id="header" class="bgimage">
      	<div id="headerinfo">
        <img src="imgs/yy.jpg" class="ui small card image imgjaco">
        <div id="headertext">
          <p id="headername"><span style="font-weight:1000">Yagya Raj Pandeya, Ph.D.</p>
          <p id="headerrole">Assistant Professor at Kathmandu University, Nepal</p>
	  <!-- <p id="headermail">yagya.pandeya@ku.edu.np</p> -->
          <!-- <p id="headermail">yagyapandeya@gmail.com</p> -->
          <div id="social-icons">
            <!-- Email reference --->
	    <a href="mailto:yagya.pandeya@ku.edu.np"><img src="imgs/mail.png"></a>
            <!-- Scholar reference --->
            <a href="https://scholar.google.com/citations?user=EYFaLysAAAAJ&hl=en"><img src="imgs/google_scholar.png"></a>
            <!-- Linkedin --->
            <a href="https://www.linkedin.com/in/yagya-pandeya-b4947116b/"><img src="imgs/linkedin.png"></a>
            <!-- Researchgate profile -->
            <a href="https://www.researchgate.net/profile/Yagya_Raj_Pandeya"><img src="imgs/rgate.png"></a>
            <!-- Github -->
            <a href="https://github.com/yagyapandeya"><img src="imgs/github.png"></a>
	<!-- ORCID -->
            <a href="https://orcid.org/0000-0002-9842-8704"><img src="imgs/orc.png"></a>
		  
          </div>
        </div>
      	</div>
    	</div>



        <div class="page">
		<div class="section row">
                <div class="contact-info col-right">
			<div><!--img src="yy.jpg" class="ui small card image imgjaco"--></div>
			<div>Citizenship: Nepal</div>
                    	<div>Permanent Address: Sukhlaphata-10, Kanchanpur, Nepal</div>
			<div>Mailing Address: Kathmandu University, Kavre, Nepal</div>
			<div>Date of birth: 25th July, 1988</div>
			<div>Phone: (+977)9848542617</div>
		    <div><a href="mailto:yagya.pandeya@ku.edu.np">yagya.pandeya@ku.edu.np</a></div>
                    <div><a href="mailto:yagyapandeya@gmail.com">yagyapandeya@gmail.com</a></div>
                </div>
            </div>
	
	<div class="section row">
                <h2 class="col">Carrier Objectives</h2>
                <div class="section-text col-right">
                    <h3><span class="emph">
			    An enthusiastic and adaptive person with a broad and acute interest in the discovery of deep learning and AI. 
			    I particularly enjoy collaborating with tech experts from different disciplines of computer science to develop new skills 
			and solve new challenges.
		    </h3>  
            </div></div>
	
	<div class="section row">
                <h2 class="col">Bio</h2>
                <div class="section-text col-right">
                    <div>I am an assistant professor in Computer science and Engineeing department at  <a href="https://ku.edu.np/">
			<span class="emph">Kathmandu University</a>, and also affiliated to the <a href="http://www.jbnu.ac.kr/eng/">
			    <span class="emph">Jeonbuk National University</a>, <a href="https://fusemachines.com/"><span class="emph">Fuse machine Nepal</a>, and <a href="http://gurutech.com.np/"><span class="emph">Guru technology</a> research group in Nepal. I have a good experience of 
				    deep learning and machine learning technologies for image, audio, music, video and text processing using supervised 
				    and unsupervised classification, multi-level classification, self-supervised learning, meta-learning, incremental learning 
				    and generative networks (GAN, VAE), which are some of my major interest areas.  
			</div>
			<div>My current project consists of applying deep learning methods in the field of animal sound behavior analysis, 
				music information retrieval, music video emotion analysis, music source separation, visual object detection, 
				music melody and rhythm pattern recognition, music rhythm segmentation and transcription, cross-cultural music 
				video emotion analysis and multi-dimensional information processing (multi-label, multi-task and multi-modal for 
				audio, video and text data), with the aim of devising quantitative measures in affective computing, object 
				detection and event localization. In the visual and remote sensing domain, we are working on pine wilt disease 
				detection and strawberry disease detection. We proposed more than 10 datasets in audio and visual domain to 
				train the deep neural network and made public to support new researchers.
			</div>	
		<div>I was a <b> Global Korea Scholarship </b> scholar sponsored by the Korean Government from 2016 to 2020. Under the scholarship, 
			I received Ph.D. in Computer Engineering from Jeonbuk National University, South Korea. I was awarded by <b>Excellent Research Award 2021</b>
			    by Jeonbuk National University. My thesis work includes music video affective computing with supervised and unsupervised technology. 
			Prior to embarking on the insanity of the doctoral studies, I received an ME in Computer Engineering from the 
			<a href="https://pu.edu.np/"><span class="emph">Pokhara University</a>, Nepal.
		</div>
		<div>In my master thesis work, I worked on data communication and information processing using multiple antenna technology. I was a student listed 
			on <b> Dean’s List </b>award by Pokhara University in 2014. A few years before, I received a BE in Computer Engineering from Pokhara University, 
			with a thesis investigating home security system using microcontroller and sensor technology.  
		</div>
           
            </div></div>

            <div class="section row">
                <h2 class="col">Educations</h2>
                <div class="section-text col-right">
		<div><a href="http://www.jbnu.ac.kr/eng/"><h3><span class="emph">Jeonbuk National University</h3></a></div>
                    <div>Major in Machine Learning and Deep Neural Networks</div>
                    <div class="row">
                        <div class="col light">CGPA: 4.43/4.50</div>
                        <div class="col-right light">Sep. 2017 - Feb. 2021</div>
                    </div>
		<div><a href="https://pu.edu.np/"><h3><span class="emph">Pokhara University</h3></a></div>
                    <div><a href="https://ncit.edu.np/">Nepal College of Information Technology, Balkumari, Lalitpur(PU Affiliated College)</a></div>
                    <div class="row">
                        <div class="col light">Rank: Dean's List (CGPA: 3.97/4)</div>
                        <div class="col-right light">Aug. 2010 to May 2013 </div>
                    </div>
		
		<div><a href="https://pu.edu.np/"><h3><span class="emph">Pokhara University(PU)</h3></a></div>
                    <div><a href="http://nast.edu.np/">National Academy of Science and Technology, Dhangadhi, Kailali(PU Affiliated College)</a></div>
                    <div class="row">
                        <div class="col light">Rank: CGPA: 3.54/4</div>
                        <div class="col-right light">Aug. 2005 to Oct. 2010 </div>
                    </div>
		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB)</h3></a></div>
                    <div><a href="http://radianths.edu.np/">Radiant Secondary School, Mahendranagar, Kanchanpur(Under NEB)(Class XII)</a></div>
                    <div class="row">
                        <div class="col light">OVERALL PERCENTAGE: 55%</div>
                        <div class="col-right light">2005 </div>
                    </div>
		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB)</h3></a></div>
                    <div>Shree Radha-Krishna Secondary School, Tiltali, Doti(Under Government of Nepal)(Class X)</div>
                    <div class="row">
                        <div class="col light">OVERALL PERCENTAGE: 74%</div>
                        <div class="col-right light">2003 </div>
                    </div>
                </div>
            </div>

	<div class="section row">
                <h2 class="col">WORK EXPERIENCES</h2>
                <div class="section-text col-right">
			
		<div><a href="https://ku.edu.np/"><h3><span class="emph">Kathmandu University (AI Program Coordinator)</h3></a></div>
                    <div>AI based teaching and research</div>
		<div>Address: Kavrepalanchok, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: Assistant Professor </div>
                        <div class="col-right light"> 01 March 2022 - Ongoing </div>
                    </div>
			
		<div><a href="http://ailab.jbnu.ac.kr/"><h3><span class="emph">Fuzzy Logic and Artificial Intelligence Laboratory at Jeonbuk National University</h3></a></div>
                    <div>Machine learning and Deep learning based research</div>
		<div>Address: Jeonju City, South Korea</div>
                    <div class="row">
                        <div class="col light">Status: Researcher </div>
                        <div class="col-right light"> 01 March 2021 - 28 Feb. 2022</div>
                    </div>
		
		<div><a href="https://gurutech.com.np/"><h3><span class="emph">Guru Technology</h3></a></div>
                    <div> Deep learning based research and advisor. </div>
			<div>Address: Kathmandu, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: Director of Research & Technology </div>
                        <div class="col-right light">01 March 2018 - Ongoing </div>
                    </div>

		<div><a href="http://www.moha.gov.np/"><h3>Ministry of Home Affairs (Government of Nepal)</h3></a></div>
                    <div>National Information Collection and Transfer </div>
			<div>Address: Singhdurbar, Kathmandu, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: IT officer</div>
                        <div class="col-right light">27 April 2015 - Aug 22 2016</div>
                    </div>
		
		<div><a href="http://nast.edu.np/"><h3><span class="emph">NAST Engineering College</h3></a></div>
                    <div>Assistant Professor and Department head. </div>
			<div>Address: Dhangadhi, Kailali, Nepal</div>
                    <div class="row">
                        <div class="col light">Status: Head of Department</div>
                        <div class="col-right light">12 Feb 2013 - 27 April 2015</div>
                    </div>
		
                </div>
            </div>


            <div class="section row">
                <h2 class="col">PROJECTS</h2>
		    
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Rhythm Segmentation</h3>
                        </div>
                    </div>
                        <div class="col-right light">Jan. 2022 - June 2022</div>
			
			<div class="col-md-5">
			<div class="pubimg">
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://www.mdpi.com/2076-3417/12/19/9571">Tracking the Rhythm: Pansori Rhythm Segmentation and Classification Methods and Datasets.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music rhythm classification and segmetation dataset.</li>
                        <li>Korean traditional music (Pansori) dataset.</li>
                        <li>Classification and semantic segmentation methods for music rhythm segmentation.</li>
			<li>HRnet, Novel optimized network and DeepLabV3 network architectures.</li>
			<li>Puplished on <b><a href="https://www.mdpi.com/journal/applsci"> Applied Sciences (MDPI) </a></b>in Sep., 2022</li>
               
		</div>
			    
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Source Separation</h3>
                        </div>
                    </div>
                        <div class="col-right light">Oct. 2021 - Feb. 2022</div>
			
			<div class="col-md-5">
			<div class="pubimg">
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://link.springer.com/article/10.1007/s00034-022-02166-5">High-Resolution Representation Learning and Recurrent Neural Network for Singing Voice Separation.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music source separation using novel dataset.</li>
                        <li>Modified HRnet and ablation study.</li>
                        <li>Comparation on public dataset and state of art result.</li>
			<li>Puplished on <b><a href="https://www.springer.com/journal/34"> Circuits, Systems, and Signal Processing (Springer) </a></b>in Sep., 2022</li>
               
		</div>
		
			
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music genre calssification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2020 - Sep. 2021</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/Jeju_conf.JPG" scale:2> 
       		 	</div>
			</div>


                    <ul class="desc">
                        <li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9620826">Multi-modal, Multi-task and Multi-label for Music Genre Classification and Emotion Regression.</a></b><b><span style="color:#FF5733;">[IEEE Conference]</span></b></li>
                        <li>Multimodal, multi-task and multi-label DNN.</li>
			<li>Optimized neural network.</li>
                        <li>44 Class categores of music genra.</li>
			<li>Puplished on <b><a href="https://ieeexplore.ieee.org/xpl/conhome/9620727/proceeding/"> ICTC2021 </a></b>in Dec. 2021</li>
               
                    </div>
	
			
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Plant Disease Classification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Oct. 2020 - March 2021</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/Jeju_conf.JPG" scale:2> 
       		 	</div>
			</div>


                    <ul class="desc">
                        <li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9621090">An Incremental Learning for Plant Disease classification.</a></b><b><span style="color:#FF5733;">[IEEE Conference]</span></b></li>
                        <li>Life-long learning method in DNN.</li>
			<li>ResNet18 and ResNet50 neural network.</li>
                        <li>High performance.</li>
			<li>Puplished on <b><a href="https://ieeexplore.ieee.org/xpl/conhome/9620727/proceeding/"> ICTC2021 </a></b>in Dec. 2021</li>
               
                    </div>
			

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Affective Computing (Unsupervised)</h3>
                        </div>
                    </div>
                        <div class="col-right light">Sep. 2020 - Jan. 2021</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/cfs_mv.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://www.nature.com/articles/s41598-021-98856-2">Music video Emotion Classification using Slow-fast Audio-video Network and Unsupervised Feature Representation.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Unsupervised and supervised music video emotion classification dataset</li>
                        <li>Autoencoder architecture with audio adn video information.</li>
                        <li>Slow-fast audio-video network to capture spatial and temporal information of music and video.</li>
			<li>Train time information sharing and boosting modules.</li>
			<li>Puplished on <b><a href="https://www.nature.com/srep/"> Scientific reports (nature) </a></b>in Oct., 2021</li>
               
		</div>


		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Affective Computing (Supervised)</h3>
                        </div>
                    </div>
                        <div class="col-right light">Sep. 2020 - Jan. 2021</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/Music_video_emo.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://www.mdpi.com/1424-8220/21/14/4927">Deep-Learning-Based Multimodal Emotion Classification for Music Videos.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music video emotion classification dataset (Inproved and Extended version)</li>
                        <li>Ablation study on unimodla and multimodal using music, video and facial expression.</li>
                        <li>Network complexity reduction using novel channel and filter separable convolution.</li>
			<li>Train time information sharing and boosting modules.</li>
			<li>End-to-end training, better result on visual and statistical analysis.</li>
			<li>Puplished on <b><a href="https://www.mdpi.com/journal/sensors"> Sensors </a></b>in July, 2021</li>
               
		</div>

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Facemask States Detection</h3>
                        </div>
                    </div>
                        <div class="col-right light">Nov. 2020 - Jan. 2021</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/Face_mask.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://dl.acm.org/doi/10.1145/3468891.3468899">Deep Learning Based Face Mask Status Detection for COVID-19.</a></b><b><span style="color:#FF5733;">[Conference]</span></b></li>
                        <li>Semi-automatic visual object labeling tool </li>
                        <li>Facemask detection dataset with three cass categories of with mask, without mask and wrong weared mask.</li>
                        <li>Mask detetion using Faster-RCNN, Cascade FRCNN, FPN and Cascade FPN.</li>
			<li>Comparision, visualization and analysis of sustem ability and applications.</li>
			<li>Puplished on <b><a href="https://dl.acm.org/doi/proceedings/10.1145/3468891"> ICMLT Conference</a></b>in April 2021</li>
               
                    </div>




		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Sound Event Labeling Tool</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/Cow_GUI.JPG" scale:2> 
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://www.sciencedirect.com/science/article/pii/S1871141321004194">A Semi-automatic Sound Annotation Tool for Audio/Video data.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Semi-automatic sound event annotation tool using audio and video as input.</li>
                        <li>Automatic event detector is used to detect the audio event.</li>
                        <li>Based on the automatic detector result, an human annotation have to refine the annotation boundary.</li>
			<li>Easy to use, better audio visualization, python based and output in easy CSV data file.</li>
                        <li>Diversified annotation tool for any rare sound event.</li>
			<li>Puplished on <b><a href="https://www.sciencedirect.com/journal/livestock-science"> Livestock Science</a></b>in Feb. 2022</li>
               
                    </div>
		
		<div class="section-text col-right">
                    <div class="row">
                        <div class="col">
                            <h3>Music Source Seperation</h3>
                        </div>
                    </div>
                        <div class="col-right light">June 2020 - Nov. 2020</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/SS.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9257356">Parallel Stacked Hourglass Network for Music Source Separation.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li><b>Prepared Korean traditional song (Pansori) dataset with 3 sources.</li>
			<li>Korean traditional music Pansori dataset, MIR-1K dataset, and DSD100 dataset used in experiment. </li>
                        <li>Proposed a novel parallel stacked hourglass network (PSHN) with multiple band spectrograms.</li>
                        <li>Ablation study on proposed and past architecture.</li>
                        <li>State-of-art result.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Nov. 2020</li>
               
                    </div>

		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>CNN Based Sound Event Detection in Cowshed</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/Jeju_conf.JPG" scale:2> 
       		 	</div>
			</div>


                    <ul class="desc">
                        <li>Article title:<b><a href="http://sigongji.ictc.org/wp/SessionPaperList.asp?code=Session%20III-1">Sound Event Detection in Cowshed using Synthetic data and Convolutional Neural Network</a></b><b><span style="color:#FF5733;">[IEEE Conference]</span></b></li>
                        <li>CNN based sound event detection.</li>
			<li>Sound event annotaion tool.</li>
                        <li>Sound localization and classification.</li>
			<li>Puplished on <b><a href="http://ictc.org/"> ICTC2020 </a></b>in Sep. 2020</li>
               
                    </div>

		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Cow Sound Event Localization and Classification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/Cow_SED.JPG" scale:2> 
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9187249/">Visual Object Detector for Cow Sound Event Detection</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Cow sound event detection dataset with 4 class categories.</li>
			<li>CNN used for sound event detection using Cow sound dataset and <a href="https://urbansounddataset.weebly.com/urbansound8k.html">UrbanSound8K dataset.</a></li>
                        <li>Visual object detection architecture (F-RCNN, CF-RCNN, FPN, C-FPC) used for audio event detection (in Log Mel-Spectrogram).</li>
			<li>Compare the proposed CNN and Visual object detection architecture using three test dataset.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Sep. 2020</li>
               
                    </div>
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music-Video Emotion Classification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Jan. 2019 - Sep. 2019</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/I3D_CNN.JPG" scale:2> 
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://link.springer.com/article/10.1007/s11042-020-08836-3">Deep Learning-Based Late Fusion of Multimodal Information for Emotion Classification of Music Video</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music-Video emotion classification using audio and video multimodal network architecture.</li>
                        <li>Use pretrained CNN for audio and 3D video model (I3D and C3D).</li>
			<li>The network learned features ate late fused and compare the impact of network feature fusion.</li>
                        <li>Cross validation and network feature fusion.</li>
			<li>Puplished on <b><a href="https://www.springer.com/journal/11042"> Multimedia Tools and Applications </a></b>in Sep. 2020</li>
               
                    </div>
		
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Emotion Analysis</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2018 - March 2019</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/mv_conf.JPG" scale:2> 
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://www.semanticscholar.org/paper/Music-Video-Emotion-Analysis-Using-Late-Fusion-of-Pandeya-Lee/594b7ec2607cf220a8d3ff64340dd5607b56ecb2">Music-Video Emotion Analysis Using Late Fusion of Multimodal</a></b><b><span style="color:#FF5733;">[Conference]</span></b></li>
                        <li>Music video emotion dataset of six class category.</li>
                        <li>Audio-video multimodal architecture.</li>
			<li>C3D pretrained network and CNN pretrained audio network feature fusion.</li>
                        <li>Emotion representation in 2D emotion space.</li>
			<li>Puplished on <b><a href="http://www.allconfs.org/meeting/index_en.asp?id=5848"> ITEEE 2019 Conference </a></b>in 2019</li>
               
                    </div>
		

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Domestic Cat Sound Classification</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2017 - Sep. 2018</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/CDBN.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://www.mdpi.com/2076-3417/8/10/1949">Domestic Cat Sound Classification Using Learned Features from Deep Neural Nets</a></b><b><span style="color:#FF5733;">[SCI Journal]</span></b></li>
                        <li>CNN and CDBN network architecture.</li>
                        <li>Cat sound dataset preparation of 10 class categories.</li>
			<li>Frequency division average pooling (FDAP) technique instead of global average pooling (GAP) to make a robust prediction using various frequency band features.</li>
                        <li>Audio augmentation and learned feature visualization.</li>
			<li>Puplished on <b><a href="https://www.mdpi.com/journal/applsci"> Applied Science </a></b>in Sep 2018</li>
               
                    </div>
		
		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Domestic Cat Sound Classification using Transfer Learning</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2017 - March 2018</div>

			<div class="col-md-5">
			<div class="pubimg">
          		<!╌ <img src="imgs/aspecus.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="http://doi.org/10.5391/IJFIS.2018.18.2.154">Domestic Cat Sound Classification Using Transfer Learning</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Cat sound dataset with 10 class categories.</li>
                        <li>Use pretrained CNN for feature extraction and make feature classification.</li>
			<li>Machine learning classifier and deep learning classifier comparision.</li>
                        <li>Ensemble and data augmentation.</li>
			<li>Puplished on <b><a href="http://www.ijfis.org/about/sub01.html"> International Journal of Fuzzy Logic and Intelligent Systems </a></b>in June 2018</li>
               
                    </div>
	</div>
	<div class="section row">
                <h2 class="col">Current Research</h2>
                <div class="section-text col-right">
                    <div><a>Multi-culture emotion analysis.</a></div>
		    <div><a>Vegetable disease detection and remedy system.</a></div>
                    <div><a>Remote sensing and GIS image analysis for agriculture field monitoring.</a></div>
                    <div><a>Wildlife activity monitoring.</a></div>
		    <div><a>Authentication system for vahicle.</a></div>

                </div>
	
	</div>
	<div class="section row">
                <h2 class="col">Books Publications</h2>
                <div class="section-text col-right">
                    <div>Yagya Raj Pandeya <a>Multimedia Information Processing using Deep Learning.</a> (Under publication)</div>
		    <div>Yagya Raj Pandeya and Sharad Chandra Joshi, <a>An Essential Guide to Computer Networks.</a> (2006, in Nepal)</div>

                </div>

            </div>
            <div class="section row">
                <h2 class="col">Achievements</h2>
                <div class="section-text col-right">

                    <div class="row subsection">
			<li><b>President's Excellent Research Award</b> of<a href="http://jbnu.ac.kr/)">Jeonbuk National University </a>(2021-02)</li>
                        <li>Winner <a href="http://www.studyinkorea.go.kr/"><b>Korean Government Scholarship Program (KGSP) </b></a>(2016)</li>
                        <li>Awarded by <b>Dean's List</b> of <a href="https://pu.edu.np/">Pokhara University</a> in 2014</li>
                            
                    </div>
                    
                </div>

            </div>
            <div class="section row">
                <h2 class="col">Language Skills</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>English Language</li>
                        <li>Korean Language</li>
                        <li>Hindi</li>
			<li>Nepali</li>
                    
                    </ul>

                    <ul class="skills" style="width:35%">
                        <li>Good</li>
                        <li>Moderate(<a href="https://www.topik.go.kr/usr/lang/index.do?home_seq=221">TOPIK</a>-3)</li>
                        <li>Native</li>
			<li>Native</li>
                        
                    </ul>
                    
                </div>
            </div>
            <div class="section row">
                <h2 class="col">Techincal Skills</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>Programming Languages</li>
                        <li>Deep learning Framework</li>
                        <li>Platforms</li>
                        <!--<li>Networking</li> -->
			<li>I.D.E Skills</li>
                    </ul>
                    <ul class="skills" style="width:35%">
                        <li>Python, C, C++, PHP</li>
                        <li>TensorFlow, Keras, PyTorch</li>
                        <li>Linux, Windows, CUDA/Docker</li>
			<li>Eclipse, UML, PyCharm </li>
                        
                    </ul>
                    
                </div>
            </div>
            
	
	<div class="section row">
                <h2 class="col">References</h2>
                <div class="section-text col-right">
		<div><a href="http://ailab.jbnu.ac.kr/intro_prof.php"><h3><span class="emph">Prof. Joonwhoan Lee</h3></a></div>
                    <div>Ph.D. Adviser</div>
			<div>Institude: <a href="https://www.jbnu.ac.kr/kor/">Jeonbuk National University</a></div>
			<div>Ph No.: +82-63-270-2406, +82-010-9855-2406</div>
			<div>Email: <a href="mailto:chlee@chonbuk.ac.kr">chlee@chonbuk.ac.kr</a></div>
		
		<div><a href="https://scholar.google.com/citations?user=S1dL69sAAAAJ&hl=en"><h3><span class="emph">Prof. Shashidhar Ram Joshi</h3></a></div>
                    <div>Master Adviser</div>
			<div>Institude: <a href="https://pu.edu.np/">Pokhara University</a></div>
			<div>Ph No.: +977-01-5534070 </div>
			<div>Email: <a href="mailto:srjoshi@ioe.edu.np">srjoshi@ioe.edu.np</a></div>
		
		<div><h3><span class="emph">Dr. Prem Bahadur Chand</h3></div>
                    <div>Undergraduate Instructor and Co-worker</div>
			<div>Institude: <a href="http://nast.edu.np/">Dhangadhi Engineeing College (Pokhara University Affiliation)</a></div>
			<div>Ph No.: +977-9858487111, 9848424687</div>
			<div>Email: prem.chand@nast.edu.np</div>
                </div>
            </div>

            </div>
        </div>
    </body>
    
            </html>
